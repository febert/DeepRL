{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-18 15:59:47,746] Site environment registry incorrect: Scoreboard did not register all envs: set(['AcrobotContinuous-v0'])\n"
     ]
    }
   ],
   "source": [
    "from dqn_learning import *\n",
    "# import cPickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-18 15:59:50,686] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating normalization by random action sampling...\n",
      "normaliztion mean [-0.00067851  0.00151578 -0.00232965 -0.01058076]\n",
      "normalization var [ 0.00983348  0.32220298  0.01067873  0.73231626]\n",
      "init_weights 0.1\n",
      "weights std = 0.5\n",
      "weights std = 0.0316227766017\n",
      "weights std = 0.0316227766017\n",
      "weights std = 0.0316227766017\n",
      "Q-learning configured in nn graph\n",
      "descending with  adam\n",
      "using environment CartPole-v0\n",
      "qnn target q-learning False False\n"
     ]
    }
   ],
   "source": [
    "car = q_learning(gamma=1., \n",
    "                 lambda_=0.9, \n",
    "#                  init_epsilon = 0.0,\n",
    "#                  update_epsilon = False,\n",
    "                 init_epsilon = 1.0,\n",
    "                 end_epsilon = 0.1,\n",
    "                 update_epsilon = True,\n",
    "                 exploration_decrease_length = 1e6,\n",
    "#                  N_0= 50, \n",
    "                 environment = 'CartPole-v0',\n",
    "                 plot_resolution = 30,\n",
    "                 nn_size_hidden = [1000,1000,1000], # [100,100] --> 0.01, [100,100,100] --> similar [400,300]\n",
    "                 nn_batch_size = 32,\n",
    "                 nn_learning_rate = 1e-2, #2.5e-4,\n",
    "                 replay_memory_size = 1e6, # larger than nn_batch_size*1e3 or doesn't train\n",
    "                 descent_method = 'adam',\n",
    "#                  dropout_keep_prob = 0.5,\n",
    "                 ema_decay_rate = 0.999,\n",
    "#                  train_frequency = 32.0\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 449 total samples 10009 train steps 0\n",
      "Length 24\n",
      "Episode 890 total samples 20026 train steps 0\n",
      "Length 38\n",
      "Episode 1333 total samples 30037 train steps 0\n",
      "Length 19\n",
      "Episode 1801 total samples 40087 train steps 253\n",
      "Length 55\n",
      "Episode 2268 total samples 50100 train steps 566\n",
      "Length 19\n",
      "Episode 2717 total samples 60102 train steps 879\n",
      "Length 30\n",
      "done training, I'm tired. I started by 0\n",
      "Episode 462 total samples 74024 train steps 1314\n",
      "Length 19\n",
      "Episode 911 total samples 84032 train steps 1626\n",
      "Length 13\n",
      "Episode 1390 total samples 94050 train steps 1940\n",
      "Length 24\n",
      "done training, I'm tired. I started by 1001\n",
      "Episode 474 total samples 106075 train steps 2315\n",
      "Length 35\n",
      "Episode 949 total samples 116087 train steps 2628\n",
      "Length 26\n",
      "Episode 1414 total samples 126108 train steps 2941\n",
      "Length 42\n",
      "done training, I'm tired. I started by 2002\n",
      "Episode 474 total samples 138092 train steps 3316\n",
      "Length 24\n",
      "Episode 967 total samples 148103 train steps 3629\n",
      "Length 13\n",
      "Episode 1460 total samples 158104 train steps 3941\n",
      "Length 24\n",
      "done training, I'm tired. I started by 3003\n",
      "1 loop, best of 3: 24.9 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit car.deepq_learning(num_iter = 10000, max_steps = 5000, max_learning_steps = 1000)#, reset_replay_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. hpc09\n",
    "    * E3-1226V3\n",
    "    * 2 \\times K620 (tf only uses 1 in this case)\n",
    "2. slu01 \n",
    "    * E5-2620V3\n",
    "    * K40c\n",
    "3. slu02\n",
    "    * E5-2620V3\n",
    "    * TITAN X\n",
    "\n",
    "** With [10,10] layers: **\n",
    "* hpc09\n",
    "    * CPU: 1 loop, best of 3: 3.14 s per loop\n",
    "    * GPU (2 x K620 ??):  1 loop, best of 3: 4.56 s per loop\n",
    "* slu01\n",
    "    * CPU: 1 loop, best of 3: 9.58 s per loop\n",
    "    * GPU: 1 loop, best of 3: 13.6 s per loop\n",
    "* slu02\n",
    "    * CPU: \n",
    "    * GPU: 1 loop, best of 3: 13.7 s per loop\n",
    "\n",
    "** With [100,100] layers: **\n",
    "* hpc09\n",
    "    * CPU: 1 loop, best of 3: 3.92 s per loop\n",
    "    * GPU (2 x K620 ??): 1 loop, best of 3: 4.8 s per loop\n",
    "* slu01\n",
    "    * CPU: 1 loop, best of 3: 10.8 s per loop\n",
    "    * GPU: 1 loop, best of 3: 13.6 s per loop\n",
    "* slu02\n",
    "    * CPU: \n",
    "    * GPU: 1 loop, best of 3: 13.9 s per loop\n",
    "\n",
    "** With [1000,1000] layers: **\n",
    "* hpc09\n",
    "    * CPU: 1 loop, best of 3: 21.4 s per loop\n",
    "    * GPU (2 x K620 ??): 1 loop, best of 3: 11.9 s per loop\n",
    "* slu01\n",
    "    * CPU: 1 loop, best of 3: 23.7 s per loop\n",
    "    * GPU: 1 loop, best of 3: 22.1 s per loop\n",
    "* slu02\n",
    "    * CPU: \n",
    "    * GPU: 1 loop, best of 3: 21.7 s per loop\n",
    "    \n",
    "** With [1000,1000,1000] layers: **\n",
    "* hpc09\n",
    "    * CPU: 1 loop, best of 3: 34.5 s per loop\n",
    "    * GPU (2 x K620 ??): 1 loop, best of 3: 16.5 s per loop\n",
    "* slu01\n",
    "    * CPU: 1 loop, best of 3: 29.5 s per loop\n",
    "    * GPU: 1 loop, best of 3: 25.5 s per loop\n",
    "* slu02\n",
    "    * CPU: \n",
    "    * GPU: 1 loop, best of 3: 24.4 s per loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the best cases it gets to perform as well as 100% random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 491 total samples 170108 train steps 4316\n",
      "Length 15\n",
      "Episode 994 total samples 180111 train steps 4629\n",
      "Length 13\n",
      "Episode 1498 total samples 190142 train steps 4942\n",
      "Length 31\n",
      "done training, I'm tired. I started by 4004\n",
      "         7235637 function calls (7207937 primitive calls) in 42.117 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000   42.123   42.123 <string>:1(<module>)\n",
      "      100    0.001    0.000    0.004    0.000 Queue.py:107(put)\n",
      "      100    0.000    0.000    0.000    0.000 Queue.py:200(_qsize)\n",
      "      100    0.000    0.000    0.000    0.000 Queue.py:204(_put)\n",
      "    64052    0.118    0.000    0.590    0.000 _methods.py:40(_all)\n",
      "    32026    0.410    0.000    1.171    0.000 box.py:27(contains)\n",
      "    32026    0.039    0.000    0.039    0.000 box.py:35(shape)\n",
      "    32026    0.531    0.000    0.798    0.000 cartpole.py:50(_step)\n",
      "     1599    0.010    0.000    0.073    0.000 cartpole.py:86(_reset)\n",
      "    30777    0.101    0.000    0.200    0.000 compat.py:27(as_bytes)\n",
      "     9000    0.010    0.000    0.010    0.000 containers.py:192(__init__)\n",
      "     8800    0.021    0.000    0.030    0.000 containers.py:237(__init__)\n",
      "   595384    1.596    0.000    3.336    0.000 containers.py:249(append)\n",
      "     4400    0.012    0.000    0.025    0.000 containers.py:280(MergeFrom)\n",
      "      200    0.001    0.000    0.001    0.000 containers.py:350(__init__)\n",
      "     5500    0.031    0.000    0.254    0.000 containers.py:368(add)\n",
      "      100    0.025    0.000    0.317    0.003 containers.py:379(extend)\n",
      "      100    0.000    0.000    0.317    0.003 containers.py:393(MergeFrom)\n",
      "     6418    0.007    0.000    0.007    0.000 contextlib.py:12(__init__)\n",
      "     6418    0.020    0.000    0.063    0.000 contextlib.py:15(__enter__)\n",
      "     6418    0.076    0.000    0.134    0.000 contextlib.py:21(__exit__)\n",
      "     6418    0.037    0.000    0.044    0.000 contextlib.py:82(helper)\n",
      "     1599    0.017    0.000    0.102    0.000 core.py:115(reset)\n",
      "    67250    0.139    0.000    0.201    0.000 core.py:80(monitor)\n",
      "    32026    0.457    0.000    2.815    0.000 core.py:86(step)\n",
      "    17600    0.066    0.000    0.124    0.000 decoder.py:117(DecodeVarint)\n",
      "    25900    0.057    0.000    0.115    0.000 decoder.py:169(ReadTag)\n",
      "     4400    1.160    0.000    6.157    0.001 decoder.py:202(DecodePackedField)\n",
      "    13700    0.028    0.000    0.069    0.000 decoder.py:238(DecodeField)\n",
      "     3300    0.008    0.000    0.011    0.000 decoder.py:297(InnerDecode)\n",
      "   605784    1.147    0.000    1.616    0.000 decoder.py:331(InnerDecode)\n",
      "     5500    0.010    0.000    0.010    0.000 decoder.py:467(_ConvertToUnicode)\n",
      "     5500    0.020    0.000    0.058    0.000 decoder.py:497(DecodeField)\n",
      "      100    0.029    0.000    7.024    0.070 decoder.py:601(DecodeRepeatedField)\n",
      "     2200    0.016    0.000    6.470    0.003 decoder.py:623(DecodeField)\n",
      "    28208    0.073    0.000    0.379    0.000 discrete.py:12(sample)\n",
      "    32026    0.101    0.000    0.135    0.000 discrete.py:14(contains)\n",
      "    33625    0.355    0.000   15.032    0.000 dqn_learning.py:130(policy)\n",
      "        1    0.598    0.598   42.123   42.123 dqn_learning.py:150(deepq_learning)\n",
      "        1    0.000    0.000    0.000    0.000 dqn_learning.py:387(plot_replay_memory_2d_state_histogramm)\n",
      "    24259    0.029    0.000    0.029    0.000 dtypes.py:132(as_numpy_dtype)\n",
      "    12836    0.050    0.000    0.101    0.000 errors.py:441(raise_exception_on_not_ok_status)\n",
      "     5005    0.012    0.000    0.020    0.000 fromnumeric.py:1162(squeeze)\n",
      "     5417    0.014    0.000    0.040    0.000 fromnumeric.py:917(argmax)\n",
      "    33625    0.140    0.000    0.174    0.000 getlimits.py:94(__new__)\n",
      "        4    0.000    0.000    0.000    0.000 ioloop.py:928(add_callback)\n",
      "       40    0.000    0.000    0.000    0.000 iostream.py:227(_is_master_process)\n",
      "       40    0.000    0.000    0.001    0.000 iostream.py:240(_schedule_flush)\n",
      "       40    0.000    0.000    0.002    0.000 iostream.py:308(write)\n",
      "      100    0.000    0.000    7.028    0.070 message.py:178(ParseFromString)\n",
      "      100    0.000    0.000    0.000    0.000 message_listener.py:77(Modified)\n",
      "    32026    0.033    0.000    0.033    0.000 monitor.py:205(_before_step)\n",
      "    32026    0.031    0.000    0.031    0.000 monitor.py:209(_after_step)\n",
      "     1599    0.002    0.000    0.002    0.000 monitor.py:225(_before_reset)\n",
      "     1599    0.002    0.000    0.002    0.000 monitor.py:229(_after_reset)\n",
      "    30777    0.070    0.000    0.148    0.000 ops.py:123(_as_graph_element)\n",
      "    84812    0.177    0.000    0.407    0.000 ops.py:1280(name)\n",
      "     5517    0.014    0.000    0.028    0.000 ops.py:1466(type)\n",
      "    30777    0.034    0.000    0.034    0.000 ops.py:1471(graph)\n",
      "    12836    0.015    0.000    0.015    0.000 ops.py:2019(version)\n",
      "    30777    0.164    0.000    0.688    0.000 ops.py:2292(as_graph_element)\n",
      "    30777    0.216    0.000    0.524    0.000 ops.py:2324(_as_graph_element_locked)\n",
      "    35293    0.030    0.000    0.030    0.000 ops.py:296(op)\n",
      "    24259    0.023    0.000    0.023    0.000 ops.py:301(dtype)\n",
      "    29776    0.067    0.000    0.100    0.000 ops.py:306(graph)\n",
      "    29776    0.241    0.000    0.532    0.000 ops.py:311(name)\n",
      "    24259    0.065    0.000    0.124    0.000 ops.py:3271(is_feedable)\n",
      "     6518    0.018    0.000    0.024    0.000 ops.py:3279(is_fetchable)\n",
      "    24259    0.022    0.000    0.022    0.000 ops.py:329(get_shape)\n",
      "    48518    0.084    0.000    0.118    0.000 ops.py:463(__hash__)\n",
      "        4    0.000    0.000    0.000    0.000 posix.py:53(wake)\n",
      "    15500    0.016    0.000    0.016    0.000 python_message.py:1004(SetListener)\n",
      "      100    0.000    0.000    7.026    0.070 python_message.py:1088(MergeFromString)\n",
      " 7800/100    0.117    0.000    7.026    0.070 python_message.py:1108(InternalParse)\n",
      " 7800/100    0.065    0.000    0.320    0.003 python_message.py:1233(MergeFrom)\n",
      "20200/15700    0.041    0.000    0.088    0.000 python_message.py:1317(Modified)\n",
      "    13300    0.026    0.000    0.037    0.000 python_message.py:1332(_UpdateOneofState)\n",
      "    20200    0.171    0.000    0.215    0.000 python_message.py:1362(__init__)\n",
      "    20000    0.021    0.000    0.025    0.000 python_message.py:1381(Modified)\n",
      "     4500    0.013    0.000    0.032    0.000 python_message.py:1397(__init__)\n",
      "     4500    0.016    0.000    0.042    0.000 python_message.py:1406(Modified)\n",
      "      200    0.001    0.000    0.002    0.000 python_message.py:415(MakeRepeatedMessageDefault)\n",
      "     8800    0.020    0.000    0.050    0.000 python_message.py:421(MakeRepeatedScalarDefault)\n",
      "     4500    0.023    0.000    0.115    0.000 python_message.py:429(MakeSubMessageDefault)\n",
      "15700/7900    0.115    0.000    0.572    0.000 python_message.py:474(init)\n",
      "      200    0.000    0.000    0.000    0.000 python_message.py:537(_GetFieldByName)\n",
      "    90329    0.174    0.000    0.245    0.000 python_message.py:651(getter)\n",
      "      200    0.001    0.000    0.002    0.000 python_message.py:660(field_setter)\n",
      "      100    0.000    0.000    0.001    0.000 python_message.py:894(Clear)\n",
      "    32026    1.151    0.000   23.128    0.001 qnn.py:431(train_batch)\n",
      "     5417    0.062    0.000   12.056    0.002 qnn.py:483(evaluate_all_actions)\n",
      "    92231    0.078    0.000    0.078    0.000 session.py:177(graph)\n",
      "     6518    0.009    0.000    0.009    0.000 session.py:282(<lambda>)\n",
      "    24259    0.027    0.000    0.027    0.000 session.py:283(<lambda>)\n",
      "     6418    0.087    0.000   26.226    0.004 session.py:287(run)\n",
      "     6518    0.025    0.000    0.055    0.000 session.py:495(_assert_fetchable)\n",
      "     6418    0.198    0.000    0.767    0.000 session.py:500(_process_fetches)\n",
      "     6518    0.042    0.000    0.070    0.000 session.py:502(_fetch_fn)\n",
      "     6418    0.772    0.000   26.092    0.004 session.py:553(_run)\n",
      "    24259    0.131    0.000    0.225    0.000 session.py:555(_feed_fn)\n",
      "      100    0.000    0.000    0.000    0.000 session.py:572(<lambda>)\n",
      "     6318    0.006    0.000    0.006    0.000 session.py:581(<lambda>)\n",
      "     6418    0.034    0.000   21.504    0.003 session.py:666(_do_run)\n",
      "     6418    0.113    0.000   21.448    0.003 session.py:690(_run_fn)\n",
      "     6418    0.021    0.000   21.470    0.003 session.py:713(_do_call)\n",
      "     6418    0.036    0.000    0.042    0.000 session.py:730(_extend_graph)\n",
      "     6418    0.090    0.000    0.422    0.000 session.py:770(_update_with_movers)\n",
      "    24259    0.107    0.000    0.255    0.000 session_ops.py:199(_get_handle_feeder)\n",
      "    24259    0.049    0.000    0.304    0.000 session_ops.py:219(_get_handle_mover)\n",
      "    51691    0.080    0.000    0.115    0.000 six.py:654(indexbytes)\n",
      "        4    0.000    0.000    0.000    0.000 stack_context.py:253(wrap)\n",
      "      100    0.003    0.000    7.365    0.074 summary_io.py:115(add_summary)\n",
      "      100    0.000    0.000    0.005    0.000 summary_io.py:158(add_event)\n",
      "    17841    0.058    0.000    0.077    0.000 tensor_shape.py:28(__init__)\n",
      "    35682    0.089    0.000    0.197    0.000 tensor_shape.py:358(as_dimension)\n",
      "    24259    0.146    0.000    0.373    0.000 tensor_shape.py:417(__init__)\n",
      "    22846    0.019    0.000    0.019    0.000 tensor_shape.py:462(dims)\n",
      "    22846    0.043    0.000    0.060    0.000 tensor_shape.py:467(ndims)\n",
      "    24259    0.160    0.000    0.859    0.000 tensor_shape.py:681(is_compatible_with)\n",
      "    14838    0.012    0.000    0.012    0.000 tensor_shape.py:74(value)\n",
      "    17841    0.056    0.000    0.111    0.000 tensor_shape.py:79(is_compatible_with)\n",
      "    24259    0.092    0.000    0.489    0.000 tensor_shape.py:796(as_shape)\n",
      "      100    0.000    0.000    0.000    0.000 threading.py:299(_is_owned)\n",
      "      100    0.001    0.000    0.002    0.000 threading.py:372(notify)\n",
      "      100    0.000    0.000    0.000    0.000 threading.py:63(_note)\n",
      "   595484    0.915    0.000    1.331    0.000 type_checkers.py:100(CheckValue)\n",
      "      100    0.000    0.000    0.001    0.000 type_checkers.py:118(CheckValue)\n",
      "       40    0.000    0.000    0.000    0.000 utf_8.py:15(decode)\n",
      "       40    0.000    0.000    0.000    0.000 {_codecs.utf_8_decode}\n",
      "     6418    0.016    0.000    0.016    0.000 {_pywrap_tensorflow.TF_DeleteBuffer}\n",
      "     6418    0.009    0.000    0.009    0.000 {_pywrap_tensorflow.TF_DeleteStatus}\n",
      "     6418    0.015    0.000    0.015    0.000 {_pywrap_tensorflow.TF_GetCode}\n",
      "     6418    0.031    0.000    0.031    0.000 {_pywrap_tensorflow.TF_NewBuffer}\n",
      "     6418    0.027    0.000    0.027    0.000 {_pywrap_tensorflow.TF_NewStatus}\n",
      "     6418   21.052    0.003   21.052    0.003 {_pywrap_tensorflow.TF_Run}\n",
      "   609084    0.471    0.000    0.471    0.000 {_struct.unpack}\n",
      "    20200    0.024    0.000    0.024    0.000 {_weakref.proxy}\n",
      "    30777    0.078    0.000    0.078    0.000 {getattr}\n",
      "    67254    0.062    0.000    0.062    0.000 {hasattr}\n",
      "    48518    0.034    0.000    0.034    0.000 {id}\n",
      "  1055039    0.860    0.000    0.860    0.000 {isinstance}\n",
      "    24259    0.021    0.000    0.021    0.000 {iter}\n",
      "    71773    0.057    0.000    0.057    0.000 {len}\n",
      "    32026    0.052    0.000    0.052    0.000 {math.cos}\n",
      "    32026    0.032    0.000    0.032    0.000 {math.sin}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'acquire' of 'thread.lock' objects}\n",
      "    64052    0.132    0.000    0.722    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "    32126    0.025    0.000    0.025    0.000 {method 'append' of 'collections.deque' objects}\n",
      "   627541    0.437    0.000    0.437    0.000 {method 'append' of 'list' objects}\n",
      "     5417    0.026    0.000    0.026    0.000 {method 'argmax' of 'numpy.ndarray' objects}\n",
      "    33625    1.977    0.000    2.150    0.000 {method 'choice' of 'mtrand.RandomState' objects}\n",
      "       40    0.000    0.000    0.000    0.000 {method 'decode' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "    30777    0.076    0.000    0.076    0.000 {method 'encode' of 'unicode' objects}\n",
      "     4400    0.009    0.000    0.009    0.000 {method 'extend' of 'list' objects}\n",
      "   193030    0.158    0.000    0.158    0.000 {method 'get' of 'dict' objects}\n",
      "    36336    0.036    0.000    0.036    0.000 {method 'items' of 'dict' objects}\n",
      "    29209    0.317    0.000    0.317    0.000 {method 'randint' of 'mtrand.RandomState' objects}\n",
      "    64052    0.472    0.000    0.472    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      200    0.001    0.000    0.001    0.000 {method 'release' of 'thread.lock' objects}\n",
      "      100    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "   133521    0.349    0.000    0.349    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "    20000    0.019    0.000    0.019    0.000 {method 'setdefault' of 'dict' objects}\n",
      "    10422    0.024    0.000    0.024    0.000 {method 'squeeze' of 'numpy.ndarray' objects}\n",
      "     1599    0.013    0.000    0.013    0.000 {method 'uniform' of 'mtrand.RandomState' objects}\n",
      "     6518    0.010    0.000    0.010    0.000 {method 'update' of 'set' objects}\n",
      "       40    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'write' of 'file' objects}\n",
      "   133359    0.648    0.000    0.648    0.000 {numpy.core.multiarray.array}\n",
      "    51691    0.035    0.000    0.035    0.000 {ord}\n",
      "       40    0.000    0.000    0.000    0.000 {posix.getpid}\n",
      "        7    0.000    0.000    0.002    0.000 {print}\n",
      "        1    0.000    0.000    0.000    0.000 {range}\n",
      "      100    0.000    0.000    0.001    0.000 {setattr}\n",
      "        4    0.000    0.000    0.000    0.000 {thread.get_ident}\n",
      "      100    0.000    0.000    0.000    0.000 {time.time}\n",
      "    18842    0.097    0.000    0.097    0.000 {zip}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "cProfile.run('car.deepq_learning(num_iter = 10000, max_steps = 5000, max_learning_steps = 1000)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now writing on /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-21 11:57:13,173] Site environment registry incorrect: Scoreboard did not register all envs: set(['AcrobotContinuous-v0'])\n"
     ]
    }
   ],
   "source": [
    "from dqn_learning import *\n",
    "# import cPickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-21 11:57:16,052] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating normalization by random action sampling...\n",
      "normaliztion mean [ 0.00055343  0.0041546   0.00037762 -0.00281387]\n",
      "normalization var [ 0.01080554  0.3292239   0.01060925  0.73021913]\n",
      "relu!!!!\n",
      "weights std = 0.707106781187\n",
      "bias std = 0.0\n",
      "relu!!!!\n",
      "weights std = 0.04472135955\n",
      "bias std = 0.0\n",
      "relu!!!!\n",
      "weights std = 0.04472135955\n",
      "bias std = 0.0\n",
      "weights std = 0.0316227766017\n",
      "bias std = 0.0\n",
      "Q-learning configured in nn graph\n",
      "descending with  adam\n",
      "using environment CartPole-v0\n",
      "qnn target q-learning False False\n"
     ]
    }
   ],
   "source": [
    "car = q_learning(gamma=1., \n",
    "                 lambda_=0.9, \n",
    "#                  init_epsilon = 0.0,\n",
    "#                  update_epsilon = False,\n",
    "                 init_epsilon = 1.0,\n",
    "                 end_epsilon = 0.1,\n",
    "                 update_epsilon = True,\n",
    "                 exploration_decrease_length = 1e6,\n",
    "#                  N_0= 50, \n",
    "                 environment = 'CartPole-v0',\n",
    "                 plot_resolution = 30,\n",
    "                 nn_size_hidden = [1000,1000,1000], # [100,100] --> 0.01, [100,100,100] --> similar [400,300]\n",
    "                 nn_batch_size = 32,\n",
    "                 nn_learning_rate = 1e-2, #2.5e-4,\n",
    "                 replay_memory_size = 1e6, # larger than nn_batch_size*1e3 or doesn't train\n",
    "                 descent_method = 'adam',\n",
    "#                  dropout_keep_prob = 0.5,\n",
    "                 ema_decay_rate = 0.999,\n",
    "#                  train_frequency = 32.0\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2225 total samples 50018 train steps 1\n",
      "Length 13\n",
      "Episode 2678 total samples 60053 train steps 314\n",
      "Length 87\n",
      "Episode 3107 total samples 70058 train steps 627\n",
      "Length 13\n",
      "Episode 3544 total samples 80060 train steps 939\n",
      "Length 35\n",
      "done training, I'm tired. I started by 0\n",
      "Episode 445 total samples 92030 train steps 1313\n",
      "Length 22\n",
      "Episode 880 total samples 102039 train steps 1626\n",
      "Length 19\n",
      "Episode 1311 total samples 112041 train steps 1939\n",
      "Length 20\n",
      "done training, I'm tired. I started by 1001\n",
      "Episode 427 total samples 124073 train steps 2315\n",
      "Length 47\n",
      "Episode 874 total samples 134084 train steps 2628\n",
      "Length 24\n",
      "Episode 1325 total samples 144093 train steps 2940\n",
      "Length 29\n",
      "done training, I'm tired. I started by 2002\n",
      "Episode 451 total samples 156086 train steps 3315\n",
      "Length 24\n",
      "Episode 886 total samples 166093 train steps 3628\n",
      "Length 12\n",
      "Episode 1347 total samples 176099 train steps 3941\n",
      "Length 26\n",
      "done training, I'm tired. I started by 3003\n",
      "1 loop, best of 3: 14 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit car.deepq_learning(num_iter = 10000, max_steps = 5000, max_learning_steps = 1000)#, reset_replay_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. hpc09\n",
    "    * E3-1226V3\n",
    "    * 2 \\times K620 (tf only uses 1 in this case)\n",
    "2. slu01 \n",
    "    * E5-2620V3\n",
    "    * K40c\n",
    "3. slu02\n",
    "    * E5-2620V3\n",
    "    * TITAN X\n",
    "\n",
    "** With [10,10] layers: **\n",
    "* hpc09\n",
    "    * CPU: 1 loop, best of 3: 3.14 s per loop\n",
    "        * tmp: 1 loop, best of 3: 2.83 s per loop\n",
    "    * GPU (2 x K620 ??):  1 loop, best of 3: 4.56 s per loop\n",
    "        * tmp: 1 loop, best of 3: 3.77 s per loop\n",
    "* slu01\n",
    "    * CPU: 1 loop, best of 3: 9.58 s per loop\n",
    "        * tmp: \n",
    "    * GPU: 1 loop, best of 3: 13.6 s per loop\n",
    "        * tmp: \n",
    "* slu02\n",
    "    * CPU: \n",
    "        * tmp: \n",
    "    * GPU: 1 loop, best of 3: 13.7 s per loop\n",
    "        * tmp: \n",
    "\n",
    "** With [100,100] layers: **\n",
    "* hpc09\n",
    "    * CPU: 1 loop, best of 3: 3.92 s per loop\n",
    "        * tmp: 1 loop, best of 3: 3.35 s per loop\n",
    "    * GPU (2 x K620 ??): 1 loop, best of 3: 4.8 s per loop\n",
    "        * tmp: 1 loop, best of 3: 3.8 s per loop\n",
    "* slu01\n",
    "    * CPU: 1 loop, best of 3: 10.8 s per loop\n",
    "        * tmp: \n",
    "    * GPU: 1 loop, best of 3: 13.6 s per loop\n",
    "        * tmp: \n",
    "* slu02\n",
    "    * CPU: \n",
    "        * tmp: \n",
    "    * GPU: 1 loop, best of 3: 13.9 s per loop\n",
    "        * tmp: \n",
    "\n",
    "** With [1000,1000] layers: **\n",
    "* hpc09\n",
    "    * CPU: 1 loop, best of 3: 21.4 s per loop\n",
    "        * tmp: 1 loop, best of 3: 17.8 s per loop\n",
    "    * GPU (2 x K620 ??): 1 loop, best of 3: 11.9 s per loop\n",
    "        * tmp: 1 loop, best of 3: 8.25 s per loop\n",
    "* slu01\n",
    "    * CPU: 1 loop, best of 3: 23.7 s per loop\n",
    "        * tmp: \n",
    "    * GPU: 1 loop, best of 3: 22.1 s per loop\n",
    "        * tmp: \n",
    "* slu02\n",
    "    * CPU: \n",
    "        * tmp: \n",
    "    * GPU: 1 loop, best of 3: 21.7 s per loop\n",
    "        * tmp: \n",
    "    \n",
    "** With [1000,1000,1000] layers: **\n",
    "* hpc09\n",
    "    * CPU: 1 loop, best of 3: 34.5 s per loop\n",
    "        * tmp: 1 loop, best of 3: 29.3 s per loop\n",
    "    * GPU (2 x K620 ??): 1 loop, best of 3: 16.5 s per loop\n",
    "        * tmp: 1 loop, best of 3: 11.8 s per loop\n",
    "* slu01\n",
    "    * CPU: 1 loop, best of 3: 29.5 s per loop\n",
    "        * tmp: \n",
    "    * GPU: 1 loop, best of 3: 25.5 s per loop\n",
    "        * tmp: 1 loop, best of 3: 14.3 s per loop\n",
    "* slu02\n",
    "    * CPU: \n",
    "        * tmp: \n",
    "    * GPU: 1 loop, best of 3: 24.4 s per loop\n",
    "        * tmp: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
